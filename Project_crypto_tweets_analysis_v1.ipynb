{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo - will remove this section before submittion \n",
    "* Todo 1\n",
    "* change code using without for loops\n",
    "\n",
    "Kavya github link\n",
    "https://github.com/KavyaOS/Cryptocurrency_Analysis_PricePrediction.git\n",
    "\n",
    "Errors while running Kavya nottebook:\n",
    "1.  ModuleNotFoundError: No module named 'plotly'\n",
    "sol: \n",
    "pip install plotly\n",
    "\n",
    "2. ModuleNotFoundError: No module named 'keras'\n",
    "\n",
    "sol:\n",
    "pip install keras\n",
    "\n",
    "3. ImportError: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`\n",
    "pip install tensorflow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prof notes - \n",
    "Given that everyone going different things for the project I want you to add a short  description in your notebook. There are up to six things that I want.\n",
    "\n",
    "First if you are working on a team then include the names and Red IDs of both team members at the top of the readme file. Just have one person submit the project so I donâ€™t end up grading the same project twice.\n",
    "\n",
    "Second a brief description of what the project does. What are the goals of your assignment? Did you succeed? What did you learn. In the assignments I knew what you were to do. So if you just had code and tables I could figure things out. In your project you need to explain what your code is doing and what the output of your code means. In Jupyter notebooks you can use markdown cells to contain text. Use the markdown cells to to explain your code and results as they are easier to read then comments in code. Use the markdown cells to add headers (Introduction, How to Run, Results, etc) to give the notebook some structure.  \n",
    "\n",
    "Third any special instructions that I need to run the project. \n",
    "\n",
    "Fourth if you use any third party libraries list them and give the pip command needed to install them. A sentence or two on what the library does for you. If your idea comes from a site like Kaggle include a link to it. \n",
    "\n",
    "Fifth a list know issues with the project. If a feature is not working let me know. If a feature is not working I will grade it more severe than if you do not tell me.\n",
    "\n",
    "Six do not upload large data files. If your total upload to the course portal is 5 MB you will be fine. If people start uploading large files to the course portal the server will crash causing you and other people in the class to panic. (I need to rewrite that server.) If you data file puts you over that limit add a command in your jupyter notebook that will  download your data file from its source. The following command in a code cell on a Unix machine will download covid data at the given https address to the local file covid.csv.\n",
    "\n",
    "\n",
    "!curl -o covid.csv https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv \n",
    "\n",
    "\n",
    "If your code takes a long time to run on the original data set then I would like a smaller dataset to run while grading. If the file is small enough it can be combined with your notebook and up loaded. If not provide a method to download the file: dropbox link, Google drive link, etc. If you are not able to do this contact me to make other arrangements. Always include a link to access the original data set file.\n",
    "\n",
    "\n",
    "As with assignments and the exam you will submit the project to the course portal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Big Data CS649 Project -  Kavya and Sachin Kumar (RedIds - 825893660 and 823431551)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info\n",
    "\n",
    "### Objective :\n",
    "- Analysing the trend of crypto currency for the last few years.\n",
    "- Cryptocurrency price Prediction using Deep learning. (for example ML models - Linear Regression,  K-Nearest Neighbors.)\n",
    "- Analysis of social media on the crypto prize. Sentiments using few keywords in the tweets and relate with the currency price.  Positive, negative or neutral emotions.\n",
    "- Our main focus would be on Twitter and Bit-coin. We can explore more currencies and platforms if time permits. \n",
    "\n",
    "\n",
    "### Datasets :\n",
    "- Tweets dataset : https://www.kaggle.com/alaix14/bitcoin-tweets-20160101-to-20190329\n",
    "    - Contains all the bitcoin tweets\n",
    "    - date range is from 2016-Jan-01 to 2019-March-29\n",
    "    \n",
    "### Special Library/Packages installed : \n",
    "- TextBlob\n",
    "    - pip install -U textblob\n",
    "    - https://textblob.readthedocs.io/en/dev/install.html\n",
    "- Language detector and translator\n",
    "    - pip install google_trans_new\n",
    "    - https://github.com/lushan88a/google_trans_new\n",
    "- pip install pandas-profiling\n",
    "- conda install graphviz\n",
    "- #todo : might need to delete below packages\n",
    "- pip install atoti \n",
    "- pip install atoti-aws\n",
    "\n",
    "\n",
    "\n",
    "### Approach :\n",
    "\n",
    "\n",
    "### Chalenges :\n",
    " - Not able to install few packages on windows like whatthelang\n",
    "    - Language Prediction\n",
    "    - https://github.com/indix/whatthelang\n",
    "    - pip install -r requirements.txt\n",
    "    - pip install whatthelang\n",
    " - Google translator stopped translating the tweets after certain time with below error.\n",
    "    - Error - \"Our systems have detected unusual traffic from your computer network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U textblob\n",
    "# ! pip install google_trans_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "\n",
    "\n",
    "######### Dataset file paths ###########\n",
    "bitcoin_tweets_dataset_filepath = '../input_datasets/tweets.csv'\n",
    "processed_bitcoin_tweets_dataset_filepath = '../input_datasets/tweets_processed.csv'\n",
    "processed_bitcoin_tweets_dataset_filepath = '../input_datasets/tweets_processed_v5_100000_eng.csv'\n",
    "\n",
    "\n",
    "\n",
    "def read_and_clean_input_file(input_file):\n",
    "    \n",
    "    # todo : using small dataset for the devlopment purpose\n",
    "    bitcoin_tweets_dataset_df_raw = pd.read_csv(\n",
    "        input_file, \n",
    "        sep=';',\n",
    "        nrows=100000,\n",
    "#         dtype={'text': str},\n",
    "        converters={'text': str},\n",
    "        usecols=['timestamp', 'text'],                            \n",
    "        index_col=[\"timestamp\"])\n",
    "    \n",
    "#     display(bitcoin_tweets_dataset_df_raw)\n",
    "#     display(bitcoin_tweets_dataset_df_raw.info())\n",
    "\n",
    "    \n",
    "    # Strip time information from the column 'timestamp' if any\n",
    "#     bitcoin_tweets_dataset_df_raw['timestamp'] = pd.to_datetime(bitcoin_tweets_dataset_df_raw['timestamp']).dt.date\n",
    "    bitcoin_tweets_dataset_df_raw.index = pd.Series(pd.to_datetime(bitcoin_tweets_dataset_df_raw.index)).dt.date\n",
    "    \n",
    "#     display(bitcoin_tweets_dataset_df_raw)\n",
    "#     display(bitcoin_tweets_dataset_df_raw.info())\n",
    "    \n",
    "    # df['timestamp'] = df['timestamp'].astype('datetime64[ns]')\n",
    "    return bitcoin_tweets_dataset_df_raw\n",
    "\n",
    "\n",
    "def filter_by_daterange(df):\n",
    "    start_date = pd.to_datetime(\"2017-03-01\").date()\n",
    "    end_date = pd.to_datetime(\"2019-03-29\").date()\n",
    "    filtered_date_range = (df.index >= start_date) & (df.index <= end_date)\n",
    "    df = df[filtered_date_range]\n",
    "    ### Filter only Business day\n",
    "    is_business_day = BDay().is_on_offset\n",
    "    filtered_business_days = pd.to_datetime(df.index).map(is_business_day)\n",
    "    df[filtered_business_days]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-27</th>\n",
       "      <td>Ãˆ appena uscito un nuovo video! LES CRYPTOMONN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-27</th>\n",
       "      <td>Cardano: Digitize Currencies; EOS https://t.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-27</th>\n",
       "      <td>Another Test tweet that wasn't caught in the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-27</th>\n",
       "      <td>Current Crypto Prices! \\n\\nBTC: $8721.99 USD\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-27</th>\n",
       "      <td>Spiv (Nosar Baz): BITCOIN Is An Asset &amp;amp; NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-11</th>\n",
       "      <td>Never, ever touch bitcoin investments,bound to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-11</th>\n",
       "      <td>ðŸ˜‚ðŸ˜‚ðŸ˜‚ facts #bitcoin https://t.co/mmI634HtKc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-11</th>\n",
       "      <td>BitcoinLend Airdropping 1,000,000 BLEND ($1,00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-11</th>\n",
       "      <td>#inzura #tokensale\\nNow is good time to get ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-11</th>\n",
       "      <td>XRP, Bitcoin and other coins to be made availa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text\n",
       "timestamp                                                    \n",
       "2019-05-27  Ãˆ appena uscito un nuovo video! LES CRYPTOMONN...\n",
       "2019-05-27  Cardano: Digitize Currencies; EOS https://t.co...\n",
       "2019-05-27  Another Test tweet that wasn't caught in the s...\n",
       "2019-05-27  Current Crypto Prices! \\n\\nBTC: $8721.99 USD\\n...\n",
       "2019-05-27  Spiv (Nosar Baz): BITCOIN Is An Asset &amp; NO...\n",
       "...                                                       ...\n",
       "2019-05-11  Never, ever touch bitcoin investments,bound to...\n",
       "2019-05-11         ðŸ˜‚ðŸ˜‚ðŸ˜‚ facts #bitcoin https://t.co/mmI634HtKc\n",
       "2019-05-11  BitcoinLend Airdropping 1,000,000 BLEND ($1,00...\n",
       "2019-05-11  #inzura #tokensale\\nNow is good time to get ri...\n",
       "2019-05-11  XRP, Bitcoin and other coins to be made availa...\n",
       "\n",
       "[100000 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100000 entries, 2019-05-27 to 2019-05-11\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    100000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2009, 1, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 5, 27)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-12</th>\n",
       "      <td>#Bitcoin #Satoshi #crypto #blockchain #Airdrop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11</th>\n",
       "      <td>I didnt tether at $7300 #iamspartacus\\n$btc $e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-21</th>\n",
       "      <td>#Bitcoin #Satoshi #crypto #blockchain #Airdrop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-09</th>\n",
       "      <td>#Bitcoin #Satoshi #crypto #blockchain #Airdrop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-12</th>\n",
       "      <td>#Bitcoin #crypto #Airdrop\\nNew Airdrop #p2pb2b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-28</th>\n",
       "      <td>How the \"Times\" have changed - great to see su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08</th>\n",
       "      <td>My weekly #Bitcoin and #crypto report for Bitc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-25</th>\n",
       "      <td>Why gift cards are scams:\\n1) turns liquid cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08</th>\n",
       "      <td>Only 1% of the world's water supply is usable,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-03</th>\n",
       "      <td>Max Gravitt joins DRIFE as a Lead Blockchain D...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2014 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text\n",
       "timestamp                                                    \n",
       "2019-03-12  #Bitcoin #Satoshi #crypto #blockchain #Airdrop...\n",
       "2018-09-11  I didnt tether at $7300 #iamspartacus\\n$btc $e...\n",
       "2019-03-21  #Bitcoin #Satoshi #crypto #blockchain #Airdrop...\n",
       "2019-03-09  #Bitcoin #Satoshi #crypto #blockchain #Airdrop...\n",
       "2019-03-12  #Bitcoin #crypto #Airdrop\\nNew Airdrop #p2pb2b...\n",
       "...                                                       ...\n",
       "2018-12-28  How the \"Times\" have changed - great to see su...\n",
       "2019-03-08  My weekly #Bitcoin and #crypto report for Bitc...\n",
       "2018-12-25  Why gift cards are scams:\\n1) turns liquid cas...\n",
       "2019-03-08  Only 1% of the world's water supply is usable,...\n",
       "2019-03-03  Max Gravitt joins DRIFE as a Lead Blockchain D...\n",
       "\n",
       "[2014 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2014 entries, 2019-03-12 to 2019-03-03\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2014 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 31.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2017, 5, 24)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 3, 29)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########### Below function is just for anlysing the dataset #####################################################\n",
    "    \n",
    "def analysing_dataset(df):\n",
    "    display(df)\n",
    "    display(df.info())\n",
    "    display(df.index.min())\n",
    "    display(df.index.max())\n",
    "#     finding maximum and minimum date\n",
    "    \n",
    "\n",
    "########### Testing block #####################################################################################################\n",
    "bitcoin_tweets_dataset_df_cleaned = read_and_clean_input_file(bitcoin_tweets_dataset_filepath)\n",
    "analysing_dataset(bitcoin_tweets_dataset_df_cleaned)\n",
    "bitcoin_tweets_dataset_df_cleaned = filter_by_daterange(bitcoin_tweets_dataset_df_cleaned)\n",
    "analysing_dataset(bitcoin_tweets_dataset_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_trans_new import google_translator  \n",
    "\n",
    "translator = google_translator() \n",
    "detector = google_translator()  \n",
    "\n",
    "def add_english_translated_tweets_to_df(df):\n",
    "    english_translated_col = []\n",
    "    df['text'] = df['text'].astype(str)\n",
    "    for tweet in df['text']:\n",
    "        if len(tweet)!=0:\n",
    "#             todo : detecotor reached to limit on 10000 records \n",
    "            detect_lang = detector.detect(tweet)\n",
    "#             detect_lang = ['en', 'english']\n",
    "            if (detect_lang != ['en', 'english']) :\n",
    "                english_translated_col.append(translator.translate(tweet,lang_tgt='en') )\n",
    "            else:\n",
    "                english_translated_col.append(tweet)\n",
    "        else:\n",
    "            english_translated_col.append(None)\n",
    "\n",
    "    df['english_translated'] = english_translated_col\n",
    "    return df\n",
    "\n",
    "############  Testing block  ##########################################\n",
    "\n",
    "# function to detect lan\n",
    "# detector = google_translator()  \n",
    "# text = \"Ãˆ appena uscito un nuovo video! LES CRYPTOMONN...\"\n",
    "# text = \"Another text which is already in english, so should not be translated.\"\n",
    "# detect_lang = 'translate all text'\n",
    "# detect_lang = detector.detect(text)\n",
    "# print(detect_lang)\n",
    "\n",
    "\n",
    "# function to translate the text to english\n",
    "# if (detect_lang != ['en', 'english']) :\n",
    "#     print(translator.translate(text,lang_tgt='en') )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_clean_filter_translate_write_file(input_file):\n",
    "    bitcoin_tweets_dataset_df_cleaned = read_and_clean_input_file(input_file)\n",
    "    bitcoin_tweets_dataset_df_cleaned = filter_by_daterange(bitcoin_tweets_dataset_df_cleaned)\n",
    "    bitcoin_tweets_dataset_df_cleaned = add_english_translated_tweets_to_df(bitcoin_tweets_dataset_df_cleaned)\n",
    "    ##### Write the processed ouput to disk. This is to avoid unnecssary english translation everytime we run the program\n",
    "    bitcoin_tweets_dataset_df_cleaned.to_csv(index=True, sep=',' , path_or_buf=processed_bitcoin_tweets_dataset_filepath)\n",
    "#     display(bitcoin_tweets_dataset_df_cleaned)\n",
    "    \n",
    "    \n",
    "############  Testing block  ##########################################  \n",
    "# read_clean_process_write_input_file(bitcoin_tweets_dataset_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed bitcoin_tweets dataset file does not exist\n"
     ]
    },
    {
     "ename": "google_new_transError",
     "evalue": "429 (Too Many Requests) from TTS API. Probable cause: Unknown",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google_trans_new\\google_trans_new.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    242\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdetect_lang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLANGUAGES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdetect_lang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://www.google.com/sorry/index?continue=https://translate.google.cn/_/TranslateWebserverUi/data/batchexecute&q=EgTHHsyWGMuy84QGIhCgljEXdVrHkGUV3hk_vX1qMgFy",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mgoogle_new_transError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fad8e3cec729>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"processed bitcoin_tweets dataset file does not exist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mread_clean_filter_translate_write_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbitcoin_tweets_dataset_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-78cf4cee4dac>\u001b[0m in \u001b[0;36mread_clean_filter_translate_write_file\u001b[1;34m(input_file)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mbitcoin_tweets_dataset_df_cleaned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_clean_input_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbitcoin_tweets_dataset_df_cleaned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_by_daterange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbitcoin_tweets_dataset_df_cleaned\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mbitcoin_tweets_dataset_df_cleaned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_english_translated_tweets_to_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbitcoin_tweets_dataset_df_cleaned\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m##### Write the processed ouput to disk. This is to avoid unnecssary english translation everytime we run the program\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mbitcoin_tweets_dataset_df_cleaned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprocessed_bitcoin_tweets_dataset_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-65e9da5813d8>\u001b[0m in \u001b[0;36madd_english_translated_tweets_to_df\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#             todo : detecotor reached to limit on 10000 records\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mdetect_lang\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#             detect_lang = ['en', 'english']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdetect_lang\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'english'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\google_trans_new\\google_trans_new.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;31m# Request successful, bad response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mgoogle_new_transError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;31m# Request failed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgoogle_new_transError\u001b[0m: 429 (Too Many Requests) from TTS API. Probable cause: Unknown"
     ]
    }
   ],
   "source": [
    "# todo: Note the seperator delimeter. orginal file has ';' and processed file has ','. \n",
    "# Should be good across complete file\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "processed_bitcoin_tweets_dataset_filepath \n",
    "\n",
    "if path.exists(processed_bitcoin_tweets_dataset_filepath):\n",
    "    print (\"processed bitcoin_tweets dataset filep exist\")\n",
    "else:\n",
    "    print (\"processed bitcoin_tweets dataset file does not exist\")\n",
    "    read_clean_filter_translate_write_file(bitcoin_tweets_dataset_filepath)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_bitcoin_tweets_dataset_df = pd.read_csv(\n",
    "        processed_bitcoin_tweets_dataset_filepath, \n",
    "        sep=',',\n",
    "#         dtype= str,\n",
    "        dtype= {'text': str, 'english_translated': str},\n",
    "#         converters={'english_translated': str},\n",
    "        index_col=[\"timestamp\"])\n",
    "    \n",
    "# processed_bitcoin_tweets_dataset_df['english_translated'] = processed_bitcoin_tweets_dataset_df['english_translated'].astype(str)\n",
    "\n",
    "# Strip time information from the column 'timestamp' if any\n",
    "# processed_bitcoin_tweets_dataset_df['timestamp'] = pd.to_datetime(processed_bitcoin_tweets_dataset_df['timestamp']).dt.date\n",
    "processed_bitcoin_tweets_dataset_df.index = pd.Series(pd.to_datetime(processed_bitcoin_tweets_dataset_df.index)).dt.date\n",
    "display(processed_bitcoin_tweets_dataset_df)\n",
    "\n",
    "\n",
    "# Filter the dates between a range which is common to both dataframes - tweets dataframe and price dataframe\n",
    "processed_bitcoin_tweets_dataset_df = filter_by_daterange(processed_bitcoin_tweets_dataset_df)\n",
    "# processed_bitcoin_tweets_dataset_df = processed_bitcoin_tweets_dataset_df.sort_index()   -- no need to sort. that is just for verification and display purpose, if needed.\n",
    "processed_bitcoin_tweets_dataset_df.sample(10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = processed_bitcoin_tweets_dataset_df\n",
    "display(temp1.index.min())\n",
    "display(temp1.index.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\"\"\" Utility function to clean tweet text by removing special characters and links using regex\"\"\"\n",
    "def clean_special_chars(text):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+://\\S+)\", \" \", text).split())\n",
    "\n",
    "\n",
    "\"\"\" Utility function to clean tweet text and remove verbose english words using nltk stopwords\"\"\"\n",
    "def clean_tweet(text):\n",
    "    text = clean_special_chars(text)\n",
    "    forbidden_words = set(stopwords.words('english'))\n",
    "    text = ' '.join(text.split('.'))\n",
    "    text = re.sub('\\/',' ',text)\n",
    "    text = text.strip('\\'\"')\n",
    "    text = re.sub(r'@([^\\s]+)',r'\\1',text)\n",
    "    text = re.sub(r'\\\\',' ',text)\n",
    "    text = text.lower()\n",
    "    text = re.sub('[\\s]+', ' ', text)\n",
    "    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',text)\n",
    "    text = re.sub(r'((http)\\S+)','',text)\n",
    "    text = re.sub(r'\\s+', ' ', re.sub('[^A-Za-z]', ' ', text.strip().lower())).strip()\n",
    "    text = re.sub(r'\\W+', ' ', text.strip().lower()).strip()\n",
    "    text = [word for word in text.split() if word not in forbidden_words]\n",
    "    return ' '.join(text)\n",
    "\n",
    "\n",
    "processed_bitcoin_tweets_dataset_df['english_keywords'] = processed_bitcoin_tweets_dataset_df['english_translated'].apply(lambda text: clean_special_chars(text))\n",
    "processed_bitcoin_tweets_dataset_df.drop(columns='english_translated', inplace=True)\n",
    "processed_bitcoin_tweets_dataset_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment(text):\n",
    "    # create TextBlob object of passed tweet text\n",
    "    text_analysis = TextBlob(text)\n",
    "    return text_analysis.sentiment.polarity\n",
    "\n",
    "processed_bitcoin_tweets_dataset_df['sentiment'] = processed_bitcoin_tweets_dataset_df['english_keywords'].apply(lambda text: sentiment(text)) # new column of sentiment\n",
    "processed_bitcoin_tweets_dataset_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter the dates between a range which is common to both dataframes - tweets dataframe and price dataframe\n",
    "# processed_bitcoin_tweets_dataset_df = filter_by_daterange(processed_bitcoin_tweets_dataset_df)\n",
    "# # processed_bitcoin_tweets_dataset_df = processed_bitcoin_tweets_dataset_df.sort_index()   -- no need to sort. that is just for verification and display purpose, if needed.\n",
    "# processed_bitcoin_tweets_dataset_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering the average tweet sentiment of the day.\n",
    "# df = df.groupby(df.index).agg(lambda x: x.value_counts().index[0])\n",
    "#  todo: played with min, max, first index.. i think mean is the best one for this.\n",
    "bitcoin_tweets_sentiment_df = processed_bitcoin_tweets_dataset_df.groupby(processed_bitcoin_tweets_dataset_df.index).mean()\n",
    "bitcoin_tweets_sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### from other notebook #######################\n",
    "%store -r big_frame\n",
    "big_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_price_df = big_frame.query(\"coin_name == 'Bitcoin'\")\n",
    "# todo : remove warning.. ... \n",
    "df1 = bitcoin_price_df['Date']\n",
    "x2  = bitcoin_price_df.loc[:,['Date']]\n",
    "x2\n",
    "bitcoin_price_df['Date'] = pd.to_datetime(df1).dt.date\n",
    "# bitcoin_price_df['Date'] = pd.to_datetime(x2).dt.date\n",
    "# bitcoin_price_df['Date'] = pd.to_datetime(x2.stack())\n",
    "\n",
    "bitcoin_price_df = bitcoin_price_df.set_index(['Date'])\n",
    "display(bitcoin_price_df)\n",
    "# display(bitcoin_price_df.info())\n",
    "\n",
    "# Filter the dates between a range. This is common to both dataframes - tweets dataframe and price dataframe\n",
    "bitcoin_price_df = filter_by_daterange(bitcoin_price_df)\n",
    "# bitcoin_price_df = bitcoin_price_df['Price'].to_frame()\n",
    "bitcoin_price_df = bitcoin_price_df[['Price', 'Change']]\n",
    "display(bitcoin_price_df)\n",
    "display(type(bitcoin_price_df))\n",
    "# display(bitcoin_price_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_bitcoin_price_and_tweets_data(bitcoin_price_df, bitcoin_tweets_sentiment_df):\n",
    "    #Combine two dataframes based on time.\n",
    "    df = pd.merge(bitcoin_price_df, bitcoin_tweets_sentiment_df, left_index=True, right_index=True, how='inner')\n",
    "    return df\n",
    "\n",
    "bitcoin_price_sentiment  = merge_bitcoin_price_and_tweets_data(bitcoin_price_df, bitcoin_tweets_sentiment_df)\n",
    "bitcoin_price_sentiment['sentiment'] = bitcoin_price_sentiment['sentiment'] * 10000\n",
    "# bitcoin_price_sentiment['sentiment'] = bitcoin_price_sentiment['sentiment']\n",
    "bitcoin_price_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot(line1, line2, label1=None, label2=None, title='', xlabel=None, ylabel=None, legend_loc='best', lw=2):\n",
    "    fig, ax = plt.subplots(1, figsize=(13, 7))\n",
    "    ax.plot(line1, label=label1, linewidth=lw)\n",
    "    ax.plot(line2, label=label2, linewidth=lw)\n",
    "    ax.set_xlabel(xlabel, fontsize=14)\n",
    "    ax.set_ylabel(ylabel, fontsize=14)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.legend(loc=legend_loc, fontsize=16)\n",
    "\n",
    "line_plot(bitcoin_price_sentiment['Price'], bitcoin_price_sentiment['sentiment'], 'Price', 'sentiment', title='Analysing tweets sentiments impact on bitcoin price ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot1(line1, line2, label1=None, label2=None, title='', xlabel=None, ylabel=None, legend_loc='best', lw=2):\n",
    "    fig, ax = plt.subplots(1, figsize=(13, 7))\n",
    "    ax.plot(line1, label=label1, linewidth=lw)\n",
    "#     ax.plot(line2, label=label2, linewidth=lw)\n",
    "    ax.set_xlabel(xlabel, fontsize=14)\n",
    "    ax.set_ylabel(ylabel, fontsize=14)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.legend(loc=legend_loc, fontsize=16)\n",
    "\n",
    "line_plot1(bitcoin_price_sentiment['Price'], None , 'Price', 'sentiment', title='Analysing tweets sentiments impact on bitcoin price ')\n",
    "line_plot1(bitcoin_price_sentiment['sentiment'], None , 'Price', 'sentiment', title='Analysing tweets sentiments impact on bitcoin price ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentiment_column_categorical(bitcoin_price_sentiment):\n",
    "    #Change 'Sentiment' column to categorical column.\n",
    "    bitcoin_price_sentiment['sentiment_cat'] = bitcoin_price_sentiment['sentiment'].astype('category')\n",
    "    bitcoin_price_sentiment['sentiment_cat'] = bitcoin_price_sentiment['sentiment_cat'].cat.codes\n",
    "    return bitcoin_price_sentiment\n",
    "\n",
    "bitcoin_price_sentiment = make_sentiment_column_categorical(bitcoin_price_sentiment)\n",
    "bitcoin_price_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_price_sentiment['sentiment_cat'] = bitcoin_price_sentiment['sentiment_cat']\n",
    "line_plot(bitcoin_price_sentiment['Price'], bitcoin_price_sentiment['sentiment_cat'], 'Price', 'sentiment_cat', title='Analysing tweets sentiments impact on bitcoin price ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
